# EXPLICATION D√âTAILL√âE DU PROJET
## TRAVAUX PRATIQUES 2 : PR√âDICTION DU CHURN CLIENT

---

## üéØ OBJECTIF DU PROJET

D√©velopper un **syst√®me complet de Machine Learning** pour pr√©dire le **churn client** (d√©sabonnement) dans une entreprise de t√©l√©communications.

### Qu'est-ce que le Churn ?

Le **churn** (ou attrition client) d√©signe le ph√©nom√®ne par lequel un client arr√™te d'utiliser les services d'une entreprise. C'est un KPI critique pour toute entreprise, particuli√®rement dans les secteurs :
- T√©l√©communications
- Banques et assurances
- Services par abonnement (streaming, SaaS)
- E-commerce

### Pourquoi est-ce important en entreprise ?

**Co√ªt d'acquisition vs r√©tention :**
- Acqu√©rir un nouveau client co√ªte **5 √† 25 fois plus cher** que de conserver un client existant
- Une am√©lioration de 5% du taux de r√©tention peut augmenter les profits de **25% √† 95%**
- Les clients fid√®les d√©pensent en moyenne **67% de plus** que les nouveaux clients

**Actions possibles avec la pr√©diction du churn :**
1. **R√©tention proactive** : Identifier les clients √† risque avant qu'ils partent
2. **Offres personnalis√©es** : Proposer des promotions cibl√©es
3. **Am√©lioration du service** : Comprendre les facteurs de d√©part
4. **Optimisation des ressources** : Concentrer les efforts sur les clients √† forte valeur

---

## üìä COMPR√âHENSION DU DATASET

### Variables du dataset T√©l√©communications

Le dataset contient des informations sur environ **7 000 clients** avec les caract√©ristiques suivantes :

#### **1. Informations D√©mographiques**
```
- gender : Sexe du client (Male/Female)
- SeniorCitizen : Senior (1) ou non (0)
- Partner : A un conjoint (Yes/No)
- Dependents : A des personnes √† charge (Yes/No)
```

**Utilit√© :** Ces variables permettent de segmenter les clients et d'identifier des patterns d√©mographiques.

#### **2. Informations sur le Compte**
```
- tenure : Anciennet√© en mois (combien de temps le client est rest√©)
- Contract : Type de contrat (Month-to-month, One year, Two year)
- PaperlessBilling : Facturation √©lectronique (Yes/No)
- PaymentMethod : M√©thode de paiement (Electronic check, Mailed check, etc.)
- MonthlyCharges : Montant factur√© mensuellement
- TotalCharges : Montant total factur√© depuis le d√©but
```

**Hypoth√®ses business :**
- Les clients avec un contrat mensuel ont plus de chances de partir
- Les clients avec une longue anciennet√© sont plus fid√®les
- Le montant des charges influence la d√©cision de rester/partir

#### **3. Services Souscrits**
```
- PhoneService : Service t√©l√©phonique (Yes/No)
- MultipleLines : Plusieurs lignes (Yes/No/No phone service)
- InternetService : Type d'Internet (DSL, Fiber optic, No)
- OnlineSecurity : S√©curit√© en ligne (Yes/No/No internet service)
- OnlineBackup : Sauvegarde en ligne (Yes/No/No internet service)
- DeviceProtection : Protection des appareils
- TechSupport : Support technique
- StreamingTV : Streaming TV
- StreamingMovies : Streaming films
```

**Hypoth√®ses business :**
- Plus un client a de services, plus il est "engag√©" et moins il risque de partir
- La qualit√© des services (notamment Internet) influence le churn

#### **4. Variable Cible**
```
- Churn : Le client est-il parti ? (Yes/No)
```

---

## üîß √âTAPES DU PROJET D√âTAILL√âES

### **√âTAPE 1 : EXPLORATION DES DONN√âES (EDA)**

```python
# Charger et examiner les donn√©es
df_churn = pd.read_csv(url)
print(df_churn.shape)  # (7043, 21) - 7043 clients, 21 variables
print(df_churn.head())
```

**Questions √† se poser :**
- Combien de clients ont quitt√© l'entreprise ?
- Quelle est la distribution des variables ?
- Y a-t-il des valeurs manquantes ?
- Y a-t-il des valeurs aberrantes ?

**Analyse du Churn :**
```python
print(df_churn['Churn'].value_counts(normalize=True))
# R√©sultat typique :
# No     0.734  ‚Üí 73.4% de clients fid√®les
# Yes    0.266  ‚Üí 26.6% de clients partis
```

**Insight :** Le dataset est **d√©s√©quilibr√©** (imbalanced). Il faudra en tenir compte lors de la mod√©lisation.

---

### **√âTAPE 2 : NETTOYAGE DES DONN√âES**

#### Probl√®me : TotalCharges contient des espaces
```python
# TotalCharges est une cha√Æne de caract√®res au lieu de num√©rique
df_churn['TotalCharges'] = pd.to_numeric(df_churn['TotalCharges'], errors='coerce')
```

**Pourquoi ?** Certaines valeurs sont des espaces vides, ce qui emp√™che les calculs.

#### G√©rer les valeurs manquantes
```python
# Imputation par la m√©diane pour TotalCharges
df_churn['TotalCharges'].fillna(df_churn['TotalCharges'].median(), inplace=True)
```

**Alternatives possibles :**
- Supprimer les lignes (si peu nombreuses)
- Imputer par la moyenne
- Imputer par un mod√®le pr√©dictif

#### Supprimer les colonnes inutiles
```python
df_churn.drop('customerID', axis=1, inplace=True)
```

**Pourquoi ?** L'ID client est unique et n'apporte aucune information pr√©dictive.

---

### **√âTAPE 3 : FEATURE ENGINEERING**

Cr√©er de nouvelles variables pour am√©liorer les pr√©dictions.

#### **Feature 1 : ChargePerMonth**
```python
df_churn['ChargePerMonth'] = df_churn['TotalCharges'] / (df_churn['tenure'] + 1)
```

**Logique :**
- Cette variable capture le **montant moyen par mois**
- Un ratio √©lev√© peut indiquer un service per√ßu comme cher
- Le `+1` √©vite la division par z√©ro pour les nouveaux clients

#### **Feature 2 : HasMultipleServices**
```python
df_churn['HasMultipleServices'] = (
    (df_churn['OnlineSecurity'] == 'Yes') | 
    (df_churn['OnlineBackup'] == 'Yes') | 
    (df_churn['DeviceProtection'] == 'Yes')
).astype(int)
```

**Logique :**
- Mesure l'**engagement** du client
- Plus de services = plus de raisons de rester
- Variable binaire : 1 si au moins un service, 0 sinon

#### **Autres features possibles (√† explorer) :**
```python
# Tenure en cat√©gories
df['TenureGroup'] = pd.cut(df['tenure'], bins=[0, 12, 24, 48, 72], 
                            labels=['0-1 an', '1-2 ans', '2-4 ans', '4+ ans'])

# Ratio charges vs anciennet√©
df['ChargeRatio'] = df['MonthlyCharges'] / df['TotalCharges']

# Nombre total de services
service_cols = ['PhoneService', 'InternetService', 'OnlineSecurity', ...]
df['TotalServices'] = df[service_cols].apply(lambda x: (x == 'Yes').sum(), axis=1)
```

---

### **√âTAPE 4 : ENCODAGE DES VARIABLES**

Les algorithmes de ML ne comprennent que les nombres, il faut donc encoder les variables cat√©gorielles.

#### **A. Label Encoding (variables binaires)**
```python
binary_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']
le = LabelEncoder()
for col in binary_cols:
    df_churn[f'{col}_encoded'] = le.fit_transform(df_churn[col])
```

**Exemple :**
```
gender         ‚Üí gender_encoded
Male           ‚Üí 1
Female         ‚Üí 0
```

**Quand l'utiliser ?** Pour des variables √† **2 cat√©gories** avec une relation ordinale (ex: No=0, Yes=1).

#### **B. One-Hot Encoding (variables multi-classes)**
```python
multi_cols = ['InternetService', 'Contract', 'PaymentMethod']
df_churn = pd.get_dummies(df_churn, columns=multi_cols, drop_first=True)
```

**Exemple :**
```
Contract              ‚Üí Contract_One year  Contract_Two year
Month-to-month        ‚Üí 0                  0
One year              ‚Üí 1                  0
Two year              ‚Üí 0                  1
```

**Pourquoi drop_first=True ?**
- √âvite la **multicolin√©arit√©**
- Si Contract_One_year=0 et Contract_Two_year=0, alors c'est forc√©ment Month-to-month

---

### **√âTAPE 5 : PR√âPARATION POUR LA MOD√âLISATION**

#### **S√©parer X (features) et y (cible)**
```python
X = df_churn[feature_cols]  # Variables ind√©pendantes
y = df_churn['Churn_encoded']  # Variable √† pr√©dire
```

#### **Split Train/Test**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```

**Param√®tres importants :**
- `test_size=0.2` : 80% train, 20% test
- `random_state=42` : Reproductibilit√©
- `stratify=y` : **CRUCIAL** - maintient la proportion du churn dans train et test

**Sans stratify :**
```
Train: 70% No, 30% Yes
Test:  80% No, 20% Yes  ‚Üê Probl√®me !
```

**Avec stratify :**
```
Train: 73.4% No, 26.6% Yes
Test:  73.4% No, 26.6% Yes  ‚Üê Proportions respect√©es
```

#### **Standardisation**
```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**Pourquoi standardiser ?**

**Avant :**
```
tenure : 1 √† 72 mois
MonthlyCharges : 18 √† 120 dollars
TotalCharges : 18 √† 8700 dollars  ‚Üê √âchelle tr√®s diff√©rente !
```

**Apr√®s standardisation :**
```
Toutes les variables : moyenne = 0, √©cart-type = 1
```

**Important :** 
- `fit_transform` sur train (apprend les param√®tres)
- `transform` seulement sur test (utilise les param√®tres du train)
- **Ne JAMAIS standardiser avant le split** (data leakage !)

---

### **√âTAPE 6 : ENTRA√éNEMENT DE PLUSIEURS MOD√àLES**

Tester diff√©rents algorithmes pour trouver le meilleur.

#### **Mod√®le 1 : R√©gression Logistique**
```python
log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train_scaled, y_train)
```

**Avantages :**
- Rapide et simple
- Interpr√©table (coefficients)
- Bon pour les relations lin√©aires

**Inconv√©nients :**
- Ne capture pas les interactions complexes
- Sensible aux features non standardis√©es

#### **Mod√®le 2 : Arbre de D√©cision**
```python
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)
```

**Avantages :**
- Tr√®s interpr√©table (visualisation)
- Pas besoin de standardisation
- Capture les interactions non-lin√©aires

**Inconv√©nients :**
- Tendance au surapprentissage
- Instable (petit changement de donn√©es ‚Üí gros changement d'arbre)

#### **Mod√®le 3 : For√™t Al√©atoire**
```python
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
```

**Avantages :**
- Tr√®s performant
- R√©sistant au surapprentissage
- G√®re bien les donn√©es manquantes
- Fournit l'importance des variables

**Inconv√©nients :**
- Moins interpr√©table
- Plus lent √† entra√Æner

#### **Mod√®le 4 : Gradient Boosting**
```python
gb = GradientBoostingClassifier(random_state=42)
gb.fit(X_train, y_train)
```

**Avantages :**
- Souvent le plus performant
- Excellent pour les comp√©titions Kaggle
- G√®re bien les d√©s√©quilibres

**Inconv√©nients :**
- Plus lent
- Risque de surapprentissage
- Beaucoup d'hyperparam√®tres

---

### **√âTAPE 7 : √âVALUATION ET COMPARAISON**

#### **M√©triques √† analyser**

Pour un probl√®me de **churn** (classification d√©s√©quilibr√©e), on privil√©gie :

**1. ROC-AUC (Area Under the Curve)**
- Mesure la capacit√© du mod√®le √† discriminer les classes
- **0.5** : mod√®le al√©atoire
- **1.0** : mod√®le parfait
- **> 0.8** : tr√®s bon mod√®le

**2. Recall (Sensibilit√©)**
- Proportion de clients partis correctement identifi√©s
- **Crucial pour le churn** : on veut d√©tecter le maximum de d√©parts

Formule : Recall = TP / (TP + FN)

**Exemple :**
```
100 clients partis r√©ellement
Mod√®le d√©tecte 80 ‚Üí Recall = 80%
20 clients partis non d√©tect√©s ‚Üê Perte !
```

**3. Precision**
- Proportion de pr√©dictions "va partir" qui sont correctes
- Important pour ne pas d√©ranger les bons clients

Formule : Precision = TP / (TP + FP)

**4. F1-Score**
- Moyenne harmonique de Precision et Recall
- √âquilibre entre les deux

**Trade-off business :**
```
Recall √©lev√© ‚Üí D√©tecter tous les d√©parts (mais faux positifs)
Precision √©lev√©e ‚Üí Cibler uniquement les vrais d√©parts (mais manquer certains)
```

**D√©cision business :** Privil√©gier le **Recall** car le co√ªt de perdre un client est √©lev√©.

---

### **√âTAPE 8 : INTERPR√âTATION ET RECOMMANDATIONS**

#### **Importance des variables**
```python
# Avec Random Forest
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf.feature_importances_
}).sort_values('Importance', ascending=False)
```

**Exemple de r√©sultats (hypoth√©tiques) :**
```
1. tenure (anciennet√©)         ‚Üí 0.25  ‚Üê Variable la plus importante
2. MonthlyCharges               ‚Üí 0.18
3. Contract_Month-to-month      ‚Üí 0.15
4. TotalCharges                 ‚Üí 0.12
5. InternetService_Fiber        ‚Üí 0.10
...
```

#### **Insights business**

**1. Anciennet√© (tenure)**
- Les nouveaux clients (< 6 mois) ont un taux de churn de 50%+
- **Action :** Programme d'onboarding renforc√© pour les 6 premiers mois

**2. Type de contrat**
- Contrats mensuels : 42% de churn
- Contrats 1 an : 11% de churn
- Contrats 2 ans : 3% de churn
- **Action :** Inciter √† passer sur des contrats longue dur√©e (r√©ductions)

**3. Montant mensuel**
- Clients payant > 70‚Ç¨/mois : risque √©lev√©
- **Action :** Offres personnalis√©es pour les "gros" clients

**4. Services additionnels**
- Clients sans services de s√©curit√© : +30% de risque
- **Action :** Promouvoir les services de valeur ajout√©e

---

## üíº APPLICATION PRATIQUE EN ENTREPRISE

### **Pipeline de production**

```python
# 1. Scorer quotidiennement tous les clients
clients_actifs = get_active_customers()
X_clients = preprocess(clients_actifs)
churn_probabilities = model.predict_proba(X_clients)[:, 1]

# 2. Identifier les clients √† risque
clients_risque = clients_actifs[churn_probabilities > 0.7]

# 3. Segmenter par niveau de risque
clients_risque['risk_level'] = pd.cut(churn_probabilities, 
                                       bins=[0.7, 0.8, 0.9, 1.0],
                                       labels=['Medium', 'High', 'Critical'])

# 4. Envoyer aux √©quipes de r√©tention
for client in clients_risque[clients_risque['risk_level'] == 'Critical']:
    send_to_retention_team(client)
    propose_special_offer(client)
```

### **Actions de r√©tention par segment**

**Clients √† risque CRITIQUE (90%+) :**
- Appel t√©l√©phonique personnalis√©
- Offre exclusive -30% pendant 6 mois
- Upgrade gratuit de service

**Clients √† risque √âLEV√â (80-90%) :**
- Email personnalis√©
- Offre -20% pendant 3 mois
- Consultation gratuite

**Clients √† risque MOYEN (70-80%) :**
- Communication automatis√©e
- Offre sur services additionnels
- Programme de fid√©lit√©

### **ROI de la pr√©diction du churn**

**Exemple chiffr√© :**
```
Base clients : 100 000
Taux de churn : 26% ‚Üí 26 000 d√©parts/an
Valeur vie client (CLV) : 500‚Ç¨

Sans pr√©diction :
Perte = 26 000 √ó 500‚Ç¨ = 13 000 000‚Ç¨

Avec pr√©diction (Recall 80%, taux r√©tention 40%) :
Clients sauv√©s = 26 000 √ó 0.80 √ó 0.40 = 8 320
Gain = 8 320 √ó 500‚Ç¨ = 4 160 000‚Ç¨

Co√ªt du programme : 500 000‚Ç¨
ROI = (4 160 000 - 500 000) / 500 000 = 732%
```

---

## üìà AM√âLIORATIONS POSSIBLES

### **1. G√©rer le d√©s√©quilibre des classes**
```python
from imblearn.over_sampling import SMOTE

# Sur-√©chantillonner la classe minoritaire
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
```

### **2. Optimiser les hyperparam√®tres**
```python
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X_train, y_train)
```

### **3. Ajuster le seuil de d√©cision**
```python
# Au lieu de 0.5, utiliser un seuil optimis√© pour le Recall
threshold = 0.3  # Plus de clients d√©tect√©s
y_pred = (y_pred_proba > threshold).astype(int)
```

### **4. Feature Engineering avanc√©**
- Tendance des charges (augmentation/diminution)
- Fr√©quence de contact avec le support
- Score de satisfaction (si disponible)
- Interactions entre variables

---

## üéì COMP√âTENCES ACQUISES

√Ä la fin de ce projet, vous ma√Ætriserez :

‚úÖ **Analyse m√©tier** : Comprendre un probl√®me business r√©el  
‚úÖ **Pr√©paration de donn√©es** : Nettoyage, encodage, feature engineering  
‚úÖ **Mod√©lisation ML** : Entra√Æner et comparer plusieurs algorithmes  
‚úÖ **√âvaluation** : Choisir les bonnes m√©triques selon le contexte  
‚úÖ **Interpr√©tation** : Traduire les r√©sultats en actions business  
‚úÖ **D√©ploiement** : Pipeline de production et monitoring  

---

## üìù EXERCICES COMPL√âMENTAIRES

**Exercice 1 :** Cr√©er une nouvelle feature "EngagementScore" combinant plusieurs services

**Exercice 2 :** Analyser l'impact du type d'Internet (Fiber vs DSL) sur le churn

**Exercice 3 :** Construire un mod√®le de scoring de 0 √† 100 pour faciliter la communication

**Exercice 4 :** Calculer le ROI d'une campagne de r√©tention bas√©e sur vos pr√©dictions

**Exercice 5 :** Cr√©er un dashboard Power BI/Tableau pour visualiser les r√©sultats